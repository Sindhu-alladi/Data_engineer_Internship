{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c23a69b-e066-4288-b6e4-271916286e19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![databricks_academy_logo.png](../Includes/images/databricks_academy_logo.png \"databricks_academy_logo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "192d769d-f0b9-4337-94a8-e4dd92895968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ingesting Data into Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "416a4d2d-7067-4522-be59-76484cb22383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Important: Select Environment 4\n",
    "The cells below may not work in other environments. To choose environment 4: \n",
    "1. Click the ![environment.png](../Includes/images/environment.png \"environment.png\") button on the right sidebar\n",
    "1. Open the **Environment version** dropdown\n",
    "1. Select **4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adf8ab50-86a3-4730-88d3-1daf57c9a949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe46141d-e3be-4af5-802b-c6a6f4f5eff9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Set python variables for catalog, schema, and volume names (change, if desired)\n",
    "catalog_name = \"dbacademy\"\n",
    "schema_name = \"ingesting_data\"\n",
    "volume_name = \"myfiles\"\n",
    "####################################################################################\n",
    "\n",
    "####################################################################################\n",
    "# Create the catalog, schema, and volume if they don't exist already\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.{volume_name}\")\n",
    "####################################################################################\n",
    "\n",
    "####################################################################################\n",
    "# Creates a file called employees.csv in the specified catalog.schema.volume\n",
    "import pandas as pd\n",
    "data = [\n",
    "    [\"1111\", \"Kristi\", \"USA\", \"Manager\"],\n",
    "    [\"2222\", \"Sophia\", \"Greece\", \"Developer\"],\n",
    "    [\"3333\", \"Peter\", \"USA\", \"Developer\"],\n",
    "    [\"4444\", \"Zebi\", \"Pakistan\", \"Administrator\"]\n",
    "]\n",
    "columns = [\"ID\", \"Firstname\", \"Country\", \"Role\"]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "file_path = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/employees.csv\"\n",
    "df.to_csv(file_path, index=False)\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8a73ad3-0469-48ce-8010-9e0941dfba99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Please note:\n",
    "We are using calls to `spark.sql()` instead of using regular SQL commands. This allows us to use python's f-strings to insert variables into the SQL commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8ae3f45-a85e-4851-9172-b975f5a34ddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Configure and Explore Your Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "373fde36-72f2-42d1-86b3-8b54b02aa516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####1. Setting Up catalog and Schema\n",
    "Set the default catalog schema. Then, view the available tables to confirm that no tables currently exist in your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dac1c16-dfc4-499c-8429-1176bf689214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set the default catalog and schema\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4773ec2-c28a-4feb-b9dc-a002234e46e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### 1A. Using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4c2b4b1-66ee-4841-b068-8996d00b19e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>default</td><td>healthcare_dataset</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "default",
         "healthcare_dataset",
         false
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "database",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "tableName",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isTemporary",
            "nullable": false,
            "type": "boolean"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 2
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isTemporary",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Display available tables in your schema\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4db4710-c034-4fe7-b120-3ea28d3f166e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### 1B. Using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b7bb316-1152-44d5-bd49-e95d00b72f1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Set the default catalog and schema (Requires Spark 3.4.0 or later)\n",
    "spark.catalog.setCurrentCatalog(catalog_name)\n",
    "spark.catalog.setCurrentDatabase(schema_name)\n",
    "\n",
    "# Display available tables in your schema\n",
    "spark.catalog.listTables(schema_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ed3a39b-6cb6-4bc6-aac0-607e8f0b35d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####2. Viewing the available files\n",
    "View the available files in your schema's **myfiles** volume. Confirm that only the **employees.csv** file is available.\n",
    "\n",
    "**NOTE:** Remember, when referencing data in volumes, use the path provided by Unity Catalog, which always has the following format: */Volumes/catalog_name/schema_name/volume_name/*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e86c0ee-0699-46fe-8290-721e1e814f6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modification_time</th></tr></thead><tbody><tr><td>/Volumes/dbacademy/ingesting_data/myfiles/employees.csv</td><td>employees.csv</td><td>137</td><td>1771405202000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "/Volumes/dbacademy/ingesting_data/myfiles/employees.csv",
         "employees.csv",
         137,
         1771405202000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modification_time",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f\"LIST '/Volumes/{catalog_name}/{schema_name}/{volume_name}/' \").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fadfd00-f979-4d34-a379-319f15131dd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Delta Lake Ingestion Techniques\n",
    "**Objective**: Create a Delta table from the **employees.csv**  file using various methods.\n",
    "\n",
    "- CREATE TABLE AS (`CTAS`)\n",
    "- UPLOAD UI (`User Interface`)\n",
    "- COPY INTO\n",
    "- AUTOLOADER (`Overview only`, `outside the scope of this module`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da434fe9-d15e-4438-87dd-aa17e4a3b41d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####1. CREATE TABLE (CTAS)\n",
    "1. Create a table from the **employees.csv** file using the CREATE TABLE AS statement similar to the previous demonstration. Run the query and confirm that the **current_employees_ctas** table was successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1cc7b5f-564f-4aba-9216-b65c72a31acd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>ingesting_data</td><td>current_employees_ctas</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ingesting_data",
         "current_employees_ctas",
         false
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isTemporary",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Drop the table if it exists for demonstration purposes\n",
    "spark.sql(f\"DROP TABLE IF EXISTS current_employees_ctas;\")\n",
    "\n",
    "#  Create the table using CTAS\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE current_employees_ctas\n",
    "AS\n",
    "SELECT ID, FirstName, Country, Role \n",
    "FROM read_files(\n",
    "  '/Volumes/{catalog_name}/{schema_name}/{volume_name}/',\n",
    "  format => 'csv',\n",
    "  header => true,\n",
    "  inferSchema => true\n",
    " );\"\"\")\n",
    "\n",
    "#  Display available tables in your schema\n",
    "spark.sql(f\"SHOW TABLES;\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb5a84c1-4dca-4f11-adbe-17b55ea8a9dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Query the **current_employees_ctas** table and confirm that it contains 4 rows and 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25390922-a4cd-42fb-a122-29d87458a000",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>FirstName</th><th>Country</th><th>Role</th></tr></thead><tbody><tr><td>1111</td><td>Kristi</td><td>USA</td><td>Manager</td></tr><tr><td>2222</td><td>Sophia</td><td>Greece</td><td>Developer</td></tr><tr><td>3333</td><td>Peter</td><td>USA</td><td>Developer</td></tr><tr><td>4444</td><td>Zebi</td><td>Pakistan</td><td>Administrator</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1111,
         "Kristi",
         "USA",
         "Manager"
        ],
        [
         2222,
         "Sophia",
         "Greece",
         "Developer"
        ],
        [
         3333,
         "Peter",
         "USA",
         "Developer"
        ],
        [
         4444,
         "Zebi",
         "Pakistan",
         "Administrator"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "FirstName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Role",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 22
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "FirstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Role",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM current_employees_ctas;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e97b9b22-9d7e-4152-a024-0f9330509366",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####2. UPLOAD UI\n",
    "The add data UI allows you to manually load data into Databricks from a variety of sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "967b7f41-480a-4cb0-83e1-41475604fb7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Complete the following steps to manually download the **employees.csv** file from your volume:\n",
    "\n",
    "   a. Select the Catalog icon ![catalog_icon.png](../../Includes/images/catalog_icon.png \"catalog_icon.png\") in the left navigation bar. \n",
    "\n",
    "   b. Select the refresh icon ![refresh_icon.png](../../Includes/images/refresh_icon.png \"refresh_icon.png\") to refresh the catalog.\n",
    "\n",
    "   c. Expand the **dbacademy** catalog. Within the catalog, you should see a variety of schemas (databases).\n",
    "\n",
    "   d. Expand **ingesting_data** schema. Notice that your schema contains **Tables** and **Volumes**.\n",
    "\n",
    "   e. Expand **Volumes** then **myfiles**. The **myfiles** volume should contain a single CSV file named **employees.csv**. \n",
    "\n",
    "   f. Click on the kebab menu on the right-hand side of the **employees.csv** file and select **Download Volume file.** This will download the CSV file to your browser's download folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d21cb9e-e6e3-47e4-8282-46706fae813e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Complete the following steps to manually upload the **employees.csv** file to your schema. This will mimic loading a local file to Databricks:\n",
    "\n",
    "   a. In the navigation bar select the **ingesting_data** schema. \n",
    "\n",
    "   b. Click the ellipses (three-dot) icon next to your schema and select **Open in Catalog Explorer**.\n",
    "\n",
    "   c. Select the **Create** drop down icon ![create_drop_down](../../Includes/images/create_drop_down.png), and select **Table**.\n",
    "\n",
    "   d. Select the **employees.csv** you downloaded earlier into the available section in the browser, or select **browse**, navigate to your downloads folder and select the **employees.csv** file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60c072c7-ae52-4eb9-8d00-9d0fa07a6a71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Complete the following steps to create the Delta table using the UPLOAD UI.\n",
    "\n",
    "   a. In the UI confirm the table will be created in the catalog **dbacademy** and the **ingesting_data** schema. \n",
    "\n",
    "   b. Under **Table name**, name the table **employees_upload**.\n",
    "\n",
    "   c. Select the **Create table** button at the bottom of the screen to create the table.\n",
    "\n",
    "   d. Confirm the table was created successfully. Then close out of the Catalog Explorer browser.\n",
    "\n",
    "**Example**\n",
    "<br></br>\n",
    "\n",
    "![create_table_ui](../../Includes/images/create_table_ui.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fac0ad9c-0695-4000-91ce-cb8a417cb4e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Use the SHOW TABLES statement to view the available tables in your schema. Confirm that the **current_employees_ui** table has been created. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07df38a1-1ea5-425f-9f77-930702207969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c07d11e-d0c1-462e-8780-2a5ef38bc162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. Lastly, query the table to review its contents.\n",
    "\n",
    "**NOTE**: If you did not upload the table using the UPLOAD UI and name it **current_employees_ui** an error will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9df50dfe-c9cc-417d-afea-0a7769cf6f7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Firstname</th><th>Country</th><th>Role</th></tr></thead><tbody><tr><td>1111</td><td>Kristi</td><td>USA</td><td>Manager</td></tr><tr><td>2222</td><td>Sophia</td><td>Greece</td><td>Developer</td></tr><tr><td>3333</td><td>Peter</td><td>USA</td><td>Developer</td></tr><tr><td>4444</td><td>Zebi</td><td>Pakistan</td><td>Administrator</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1111,
         "Kristi",
         "USA",
         "Manager"
        ],
        [
         2222,
         "Sophia",
         "Greece",
         "Developer"
        ],
        [
         3333,
         "Peter",
         "USA",
         "Developer"
        ],
        [
         4444,
         "Zebi",
         "Pakistan",
         "Administrator"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Firstname",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Role",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 24
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Firstname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Role",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM employees_upload;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6635177-e83c-4f3c-99b9-e4bdfcdda713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####3. COPY INTO\n",
    "Create a table from the **employees.csv** file using the [COPY INTO](https://docs.databricks.com/en/sql/language-manual/delta-copy-into.html) statement. \n",
    "\n",
    "The `COPY INTO` statement incrementally loads data from a file location into a Delta table. This is a retryable and idempotent operation. Files in the source location that have already been loaded are skipped. This is true even if the files have been modified since they were loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94bb27bc-ccb6-4b60-bbae-e8545c959dcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Create an empty table named **current_employees_copyinto** and define the column data types.\n",
    "\n",
    "**NOTE:** You can also create an empty table with no columns and evolve the schema with `COPY INTO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84248c0c-99d1-4b51-a384-ea500672ac7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "CreateTable"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Drop the table if it exists for demonstration purposes\n",
    "DROP TABLE IF EXISTS current_employees_copyinto;\n",
    "\n",
    "-- Create an empty table with the column data types\n",
    "CREATE TABLE current_employees_copyinto (\n",
    "  ID INT,\n",
    "  FirstName STRING,\n",
    "  Country STRING,\n",
    "  Role STRING\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df9b7453-8efc-4a97-affd-0ab4234bc3ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Use the `COPY INTO` statement to load all files from the **myfiles** volume (currently only the **employees.csv** file exists) using the path provided by Unity Catalog. Confirm that the data is loaded into the **current_employees_copyinto** table.\n",
    "   \n",
    "    Confirm the following:\n",
    "    - **num_affected_rows** is 4\n",
    "    - **num_inserted_rows** is 4\n",
    "    - **num_skipped_correct_files** is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0a127c4-a142-46f1-8fa6-1947cd61b8e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th><th>num_skipped_corrupt_files</th></tr></thead><tbody><tr><td>4</td><td>4</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4,
         4,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_skipped_corrupt_files",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "COPY INTO current_employees_copyinto\n",
    "  FROM '/Volumes/{catalog_name}/{schema_name}/{volume_name}/'\n",
    "  FILEFORMAT = CSV\n",
    "  FORMAT_OPTIONS (\n",
    "      'header' = 'true', \n",
    "      'inferSchema' = 'true'\n",
    "    )\n",
    "  \"\"\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bc015a5-80a5-4323-b729-7fe73f71535f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Query the **current_employees_copyinto** table and confirm that all 4 rows have been copied into the Delta table correctly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f5d142b-e71c-4759-885e-201c5fe8d683",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>FirstName</th><th>Country</th><th>Role</th></tr></thead><tbody><tr><td>1111</td><td>Kristi</td><td>USA</td><td>Manager</td></tr><tr><td>2222</td><td>Sophia</td><td>Greece</td><td>Developer</td></tr><tr><td>3333</td><td>Peter</td><td>USA</td><td>Developer</td></tr><tr><td>4444</td><td>Zebi</td><td>Pakistan</td><td>Administrator</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1111,
         "Kristi",
         "USA",
         "Manager"
        ],
        [
         2222,
         "Sophia",
         "Greece",
         "Developer"
        ],
        [
         3333,
         "Peter",
         "USA",
         "Developer"
        ],
        [
         4444,
         "Zebi",
         "Pakistan",
         "Administrator"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "FirstName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Role",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 27
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "FirstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Role",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM current_employees_copyinto;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bf0ee69-0639-468d-9162-731c80574cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Run the `COPY INTO` statement again and confirm that it did not re-add the data from the volume that was already loaded. Remember, `COPY INTO` is a retryable and idempotent operation â€” Files in the source location that have already been loaded are skipped.   \n",
    "    - **num_affected_rows** is 0\n",
    "    - **num_inserted_rows** is 0\n",
    "    - **num_skipped_correct_files** is 0\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd52850-a142-483c-b942-4329b4e6561f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th><th>num_skipped_corrupt_files</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_skipped_corrupt_files",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f'''\n",
    "COPY INTO current_employees_copyinto\n",
    "  FROM '/Volumes/{catalog_name}/{schema_name}/{volume_name}/'\n",
    "  FILEFORMAT = CSV\n",
    "  FORMAT_OPTIONS (\n",
    "      'header' = 'true', \n",
    "      'inferSchema' = 'true'\n",
    "    )\n",
    "  ''').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3f0fe8d-4ecd-4de0-ae85-a9d567cb5dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. Run the script below to create an additional CSV file named **employees2.csv** in your **myfiles** volume. View the results and confirm that your volume now contains two CSV files: the original **employees.csv** file and the new **employees2.csv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5497f0a-9e69-4a91-b611-b6a41c1b30ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/dbacademy/ingesting_data/myfiles/employees.csv</td><td>employees.csv</td><td>137</td><td>1771405202000</td></tr><tr><td>dbfs:/Volumes/dbacademy/ingesting_data/myfiles/employees2.csv</td><td>employees2.csv</td><td>137</td><td>1771406657000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/dbacademy/ingesting_data/myfiles/employees.csv",
         "employees.csv",
         137,
         1771405202000
        ],
        [
         "dbfs:/Volumes/dbacademy/ingesting_data/myfiles/employees2.csv",
         "employees2.csv",
         137,
         1771406657000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create the new employees2.csv file in your volume\n",
    "dbutils.fs.cp(f'/Volumes/{catalog_name}/{schema_name}/{volume_name}/employees.csv', f'/Volumes/{catalog_name}/{schema_name}/{volume_name}/employees2.csv')\n",
    "\n",
    "## View the files in the your myfiles volume\n",
    "files = dbutils.fs.ls(f'/Volumes/dbacademy/{schema_name}/myfiles')\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c48bc669-87da-4fc9-a8bb-05f67912c83c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "6. Query the new **employees2.csv** file directly. Confirm that only 2 rows exist in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a0a2fd2-26d2-4606-bfe8-0f3d4a74663c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>FirstName</th><th>Country</th><th>Role</th></tr></thead><tbody><tr><td>1111</td><td>Kristi</td><td>USA</td><td>Manager</td></tr><tr><td>2222</td><td>Sophia</td><td>Greece</td><td>Developer</td></tr><tr><td>3333</td><td>Peter</td><td>USA</td><td>Developer</td></tr><tr><td>4444</td><td>Zebi</td><td>Pakistan</td><td>Administrator</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1111,
         "Kristi",
         "USA",
         "Manager"
        ],
        [
         2222,
         "Sophia",
         "Greece",
         "Developer"
        ],
        [
         3333,
         "Peter",
         "USA",
         "Developer"
        ],
        [
         4444,
         "Zebi",
         "Pakistan",
         "Administrator"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "FirstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Role",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "SELECT \n",
    "  ID, \n",
    "  FirstName, \n",
    "  Country, \n",
    "  Role \n",
    "FROM read_files(\n",
    "  '/Volumes/{catalog_name}/{schema_name}/{volume_name}/employees2.csv',\n",
    "  format => 'csv',\n",
    "  header => true,\n",
    "  inferSchema => true\n",
    " );\"\"\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cb74380-0538-4e18-b9ec-2f70c1ec9dfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "7. Execute the `COPY INTO` statement again using your volume's path. Notice that only the 2 rows from the new **employees2.csv** file are added to the **current_employees_copyinto** table.\n",
    "\n",
    "    - **num_affected_rows** is 2\n",
    "    - **num_inserted_rows** is 2\n",
    "    - **num_skipped_correct_files** is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "924a200a-84aa-4859-aeb1-c148a4dce96e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th><th>num_skipped_corrupt_files</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_skipped_corrupt_files",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f'''\n",
    "COPY INTO current_employees_copyinto\n",
    "  FROM '/Volumes/{catalog_name}/{schema_name}/{volume_name}/'\n",
    "  FILEFORMAT = CSV\n",
    "  FORMAT_OPTIONS (\n",
    "      'header' = 'true', \n",
    "      'inferSchema' = 'true'\n",
    "    )\n",
    "  ''').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "600b2863-a0f4-4e22-aa1e-c5fbaf9fbea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "8. View the updated **current_employees_copyinto** table and confirm that it now contains 8 rows, including the new data that was added.\n",
    "\n",
    "Note that `COPY INTO` will copy duplicate data into the destination table if it exists in the source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dd9bcd4-f4dc-4e61-a222-d72f8c77fd5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>FirstName</th><th>Country</th><th>Role</th></tr></thead><tbody><tr><td>1111</td><td>Kristi</td><td>USA</td><td>Manager</td></tr><tr><td>2222</td><td>Sophia</td><td>Greece</td><td>Developer</td></tr><tr><td>3333</td><td>Peter</td><td>USA</td><td>Developer</td></tr><tr><td>4444</td><td>Zebi</td><td>Pakistan</td><td>Administrator</td></tr><tr><td>1111</td><td>Kristi</td><td>USA</td><td>Manager</td></tr><tr><td>2222</td><td>Sophia</td><td>Greece</td><td>Developer</td></tr><tr><td>3333</td><td>Peter</td><td>USA</td><td>Developer</td></tr><tr><td>4444</td><td>Zebi</td><td>Pakistan</td><td>Administrator</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1111,
         "Kristi",
         "USA",
         "Manager"
        ],
        [
         2222,
         "Sophia",
         "Greece",
         "Developer"
        ],
        [
         3333,
         "Peter",
         "USA",
         "Developer"
        ],
        [
         4444,
         "Zebi",
         "Pakistan",
         "Administrator"
        ],
        [
         1111,
         "Kristi",
         "USA",
         "Manager"
        ],
        [
         2222,
         "Sophia",
         "Greece",
         "Developer"
        ],
        [
         3333,
         "Peter",
         "USA",
         "Developer"
        ],
        [
         4444,
         "Zebi",
         "Pakistan",
         "Administrator"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "FirstName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Country",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Role",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 32
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "FirstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Role",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM current_employees_copyinto;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14b83bb7-d2f3-43ae-886e-dfaa85008f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "9. View table's history. Notice that there are 3 versions.\n",
    "    - **Version 0** is the initial empty table created by the CREATE TABLE statement.\n",
    "    - **Version 1** is the first `COPY INTO` statement that loaded the **employees.csv** file into the Delta table.\n",
    "    - **Version 2** is the second `COPY INTO` statement that only loaded the new **employees2.csv** file into the Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e53dbb4b-46b2-409c-9882-c34f757be64a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View table history (qualified)"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>queryHistoryStatementId</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>2</td><td>2026-02-18T09:25:38.000Z</td><td>75851138266010</td><td>alladisindhu24@gmail.com</td><td>COPY INTO</td><td>Map(statsOnLoad -> true)</td><td>null</td><td>List(4374631413018150)</td><td>1df367a2-f899-4ac7-852d-7596c70106d3</td><td>0218-085934-m4hjui1m-v2n</td><td>1</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1418, numSkippedCorruptFiles -> 0)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>1</td><td>2026-02-18T09:22:48.000Z</td><td>75851138266010</td><td>alladisindhu24@gmail.com</td><td>COPY INTO</td><td>Map(statsOnLoad -> true)</td><td>null</td><td>List(4374631413018150)</td><td>670f045e-3be0-4942-ac85-3c321c072814</td><td>0218-085934-m4hjui1m-v2n</td><td>0</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 4, numOutputBytes -> 1418, numSkippedCorruptFiles -> 0)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>0</td><td>2026-02-18T09:22:24.000Z</td><td>75851138266010</td><td>alladisindhu24@gmail.com</td><td>CREATE TABLE</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> true, properties -> {\"delta.parquet.compression.codec\":\"zstd\",\"delta.enableDeletionVectors\":\"true\",\"delta.enableRowTracking\":\"true\",\"delta.rowTracking.materializedRowCommitVersionColumnName\":\"_row-commit-version-col-9e93ef84-b641-4f24-8362-1cceceef6c3c\",\"delta.rowTracking.materializedRowIdColumnName\":\"_row-id-col-e61338a2-7445-4ec9-be48-12ea7d858716\"}, statsOnLoad -> false)</td><td>null</td><td>List(4374631413018150)</td><td>206ce5c9-d9fb-44ea-b6b4-f95f7dc23eee</td><td>0218-085934-m4hjui1m-v2n</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map()</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "2026-02-18T09:25:38.000Z",
         "75851138266010",
         "alladisindhu24@gmail.com",
         "COPY INTO",
         {
          "statsOnLoad": "true"
         },
         null,
         [
          "4374631413018150"
         ],
         "1df367a2-f899-4ac7-852d-7596c70106d3",
         "0218-085934-m4hjui1m-v2n",
         1,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1418",
          "numOutputRows": "4",
          "numSkippedCorruptFiles": "0"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         1,
         "2026-02-18T09:22:48.000Z",
         "75851138266010",
         "alladisindhu24@gmail.com",
         "COPY INTO",
         {
          "statsOnLoad": "true"
         },
         null,
         [
          "4374631413018150"
         ],
         "670f045e-3be0-4942-ac85-3c321c072814",
         "0218-085934-m4hjui1m-v2n",
         0,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1418",
          "numOutputRows": "4",
          "numSkippedCorruptFiles": "0"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         0,
         "2026-02-18T09:22:24.000Z",
         "75851138266010",
         "alladisindhu24@gmail.com",
         "CREATE TABLE",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "true",
          "partitionBy": "[]",
          "properties": "{\"delta.parquet.compression.codec\":\"zstd\",\"delta.enableDeletionVectors\":\"true\",\"delta.enableRowTracking\":\"true\",\"delta.rowTracking.materializedRowCommitVersionColumnName\":\"_row-commit-version-col-9e93ef84-b641-4f24-8362-1cceceef6c3c\",\"delta.rowTracking.materializedRowIdColumnName\":\"_row-id-col-e61338a2-7445-4ec9-be48-12ea7d858716\"}",
          "statsOnLoad": "false"
         },
         null,
         [
          "4374631413018150"
         ],
         "206ce5c9-d9fb-44ea-b6b4-f95f7dc23eee",
         "0218-085934-m4hjui1m-v2n",
         null,
         "WriteSerializable",
         true,
         {},
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobRunId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "queryHistoryStatementId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 5
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "queryHistoryStatementId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY dbacademy.ingesting_data.current_employees_copyinto;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89b57e41-fd19-4e09-94ff-53955fe4db54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####4. AUTO LOADER\n",
    "\n",
    "**NOTE: Auto Loader is outside the scope of this course.**\n",
    "\n",
    "Auto Loader incrementally and efficiently processes new data files as they arrive in cloud storage without any additional setup.\n",
    "\n",
    "![autoloader](../../Includes/images/autoloader.png)\n",
    "\n",
    "The key benefits of using the auto loader are:\n",
    "- No file state management: The source incrementally processes new files as they land on cloud storage. You don't need to manage any state information on what files arrived.\n",
    "- Scalable: The source will efficiently track the new files arriving by leveraging cloud services and RocksDB without having to list all the files in a directory. This approach is scalable even with millions of files in a directory.\n",
    "- Easy to use: The source will automatically set up notification and message queue services required for incrementally processing the files. No setup needed on your side.\n",
    "\n",
    "Check out the documentation\n",
    "[What is Auto Loader](https://docs.databricks.com/en/ingestion/auto-loader/index.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee863ab9-a6b1-46c6-ba31-ee1edba3c76f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. Cleanup\n",
    "1. Drop the **ingesting_data** schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56115e44-95aa-404c-9623-de3caccefa06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "DROP SCHEMA IF EXISTS {schema_name} CASCADE;\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7918592073911062,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02 - Ingesting Data into Delta Lake",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}